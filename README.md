<p align="center">
  <img src="images/logo.jpg" alt="Logo" width="300" />
</p>

<p align="center">
  <a style="color: white; font-weight: bold;">ä¸­æ–‡</a> | <a href="README_en.md">English</a>
</p>

<div align="center">
  <small><strong>æ¶µç›–ï¼šæ¨¡å‹æ­å»º - é¢„è®­ç»ƒ - ç›‘ç£å¾®è°ƒ - æ¨ç† - é‡åŒ– - éƒ¨ç½² - Agent åº”ç”¨</strong></small>
</div>

## ç®€ä»‹

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Model, LLMï¼‰ä»å¼€å‘åˆ°éƒ¨ç½²å’Œåº”ç”¨ï¼Œæ˜¯å¤šä¸ªæŠ€æœ¯ç»†åˆ†æ–¹å‘çš„èåˆè¿‡ç¨‹ï¼Œæ¶‰åŠæ¨¡å‹ç®—æ³•å·¥ç¨‹å¸ˆã€æç¤ºè¯å·¥ç¨‹å¸ˆã€Agent åº”ç”¨å¼€å‘å·¥ç¨‹å¸ˆç­‰å¤šç§è§’è‰²ã€‚æ— è®ºæœªæ¥å¸Œæœ›æ·±å…¥å“ªä¸ªæ–¹å‘ï¼Œå¯¹äºå­¦ä¹ è€…è€Œè¨€ï¼Œå…¨é¢å­¦ä¹ å¹¶å®è·µ LLM ä»æ¨¡å‹æ­å»ºã€å¼€å‘åˆ°æœ€ç»ˆå‘ˆç°ç»™ç”¨æˆ·çš„å®Œæ•´å·¥ç¨‹æµç¨‹è‡³å…³é‡è¦ã€‚è¿™ä¸ä»…æœ‰åŠ©äºåŠ æ·±å¯¹ LLM æŠ€æœ¯ä½“ç³»çš„ç†è§£ï¼Œä¹Ÿæœ‰åˆ©äºåœ¨å®é™…é¡¹ç›®ä¸­æ›´é«˜æ•ˆåœ°ä¼˜åŒ–æ¨¡å‹æ•ˆæœã€æ¨åŠ¨åº”ç”¨è½åœ°ã€‚é—æ†¾çš„æ˜¯ï¼Œç›®å‰ä»ç¼ºä¹ç³»ç»Ÿæ€§ã€å®æˆ˜æ€§å¼ºçš„æ•™å­¦èµ„æ–™æˆ–å¼€æºé¡¹ç›®ï¼Œèƒ½å¸®åŠ©è¿›é˜¶å­¦ä¹ è€…æŒæ¡ LLM å…¨æµç¨‹å¼€å‘ã€‚ä¸ºæ­¤ï¼Œæœ¬é¡¹ç›®æ—¨åœ¨å¤ç°å¹¶æ¢³ç†ä¸€å¥—å®Œæ•´çš„ LLM å¼€å‘è·¯å¾„ï¼Œæºäºæœ¬äººåœ¨å®è·µä¸­çš„ä¸æ–­æ¢ç´¢ï¼Œå¸®åŠ©æ›´å¤šå­¦ä¹ è€…å°‘èµ°å¼¯è·¯ï¼Œæœªæ¥ä¹Ÿå°†æŒç»­æ›´æ–°ä¸ä¼˜åŒ–ã€‚

- è¯¥é¡¹ç›®æ˜¯æœ¬äººè¿›é˜¶å­¦ä¹  LLM è¿‡ç¨‹ä¸­çš„å­¦ä¹ ä»£ç ï¼Œå»ºè®®å­¦ä¹ è€…åœ¨å¼€å§‹å‰å…·å¤‡ä»¥ä¸‹åŸºç¡€çŸ¥è¯†ï¼šPyTorch æ·±åº¦å­¦ä¹ ã€Transformer æ¶æ„ã€é¢„è®­ç»ƒä¸æŒ‡ä»¤å¾®è°ƒã€æ¨¡å‹é‡åŒ–ä»¥åŠ AI Agent ç­‰ç›¸å…³å†…å®¹ã€‚
- é¡¹ç›®å®Œæ•´èµ°é€šäº† LLM çš„å·¥ä¸šçº§è½åœ°å…¨æµç¨‹ï¼ŒåŒ…æ‹¬ï¼šæ¨¡å‹æ­å»ºã€é¢„è®­ç»ƒã€ç›‘ç£å¾®è°ƒã€æ¨ç†ã€é‡åŒ–ã€éƒ¨ç½²åŠ Agent åº”ç”¨å¼€å‘ã€‚
- æœ¬é¡¹ç›®å‚è€ƒå¹¶åŸºäºä»¥ä¸‹ä¸‰ä¸ªä¼˜ç§€çš„å¼€æºé¡¹ç›®è¿›è¡Œæ„å»ºä¸å®ç°ï¼š
  - [https://github.com/jingyaogong/minimind](https://github.com/jingyaogong/minimind)
  - [https://github.com/InternLM/lmdeploy](https://github.com/InternLM/lmdeploy)
  - [https://github.com/langchain-ai/langgraph-codeact](https://github.com/langchain-ai/langgraph-codeact)
- è¡·å¿ƒæ„Ÿè°¢ä»¥ä¸Šé¡¹ç›®çš„å¼€æºè´¡çŒ®è€…ï¼Œä»–ä»¬ä¸ºæœ¬é¡¹ç›®çš„æ„å»ºæä¾›äº†å®è´µçš„å‚è€ƒä¸å¯å‘ã€‚

> å¸Œæœ›æœ¬é¡¹ç›®èƒ½ä¸ºå¤§å®¶æä¾›å®ç”¨çš„å­¦ä¹ è·¯å¾„ï¼ŒåŠ©ä½ æˆä¸º LLM é¢†åŸŸçš„ä¸“å®¶ï¼

---

## å¿«é€Ÿå¼€å§‹

<details>
  <summary>æœ¬äººçš„è½¯ç¡¬ä»¶é…ç½®</summary>

  - CPU: 16 æ ¸ï¼ŒXeon(R) Gold 6430  
  - å†…å­˜: 120 GB  
  - GPU: RTX 4090 / 24 GB  
  - CUDA == 11.3  
  - Python == 3.11.13  
</details>

### â…  ç¯å¢ƒé…ç½®

```bash
conda create -n myenv python=3.11.13
conda activate myenv
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
````

### â…¡ æ•°æ®é›†ä¸‹è½½

[æ•°æ®é›†ä¸‹è½½é“¾æ¥](https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files) ï¼ˆminimind é¡¹ç›®æä¾›ï¼‰
åˆ›å»º `./dataset` ç›®å½•ï¼Œå¹¶æŠŠä¸‹è½½çš„æ•°æ®é›†æ–‡ä»¶æ”¾åˆ° `./dataset` ä¸‹ï¼Œç›´æ¥ä¸‹è½½ `pretrain_hq.jsonl` å’Œ `sft_mini_512.jsonl` ä¸¤ä¸ªæ•°æ®é›†å³å¯å¿«é€Ÿä½“éªŒé¢„è®­ç»ƒä¸ç›‘ç£å¾®è°ƒã€‚

### â…¢ åˆ†è¯å™¨ï¼ˆTokenizerï¼‰

æœ¬äººå·²ç»è®­ç»ƒå¥½äº†åˆ†è¯å™¨åœ¨ `./model/yuanmeng_tokenizer` ä¸‹ï¼Œè¯è¡¨å¤§å°ä¸º 6400ã€‚è‹¥éå¿…è¦æ— éœ€å†è‡ªè¡Œè®­ç»ƒã€‚è‹¥éœ€è¦è®­ç»ƒï¼Œè¿è¡Œ `train_tokenizer.py`ï¼Œå¹¶ç¡®ä¿è®¾å¤‡æœ‰ 95 GB ä»¥ä¸Šå†…å­˜ã€‚
æœ¬äººäº²æµ‹å†…å­˜æœ€é«˜å ç”¨ä¸º 95 GBï¼è®­ç»ƒæ—¶é—´ä¸º 22.5 åˆ†é’Ÿã€‚

```bash
python train_tokenizer.py
```

### â…£ é¢„è®­ç»ƒä¸ç›‘ç£å¾®è°ƒ

è¯¥æ­¥éª¤é¢„è®­ç»ƒå¹¶å¾®è°ƒäº†ä¸€ä¸ªâ€œç¼˜æ¢¦â€å¤§æ¨¡å‹ï¼Œä»¥æœ¬äººçš„ç½‘åå‘½åï¼Œä¸¤ä¸ªè®­ç»ƒæ­¥éª¤å‡è€—çº¦45åˆ†é’Ÿï¼ˆéƒ½æ˜¯è®­ç»ƒ 1 ä¸ª epochï¼‰ã€‚

**ç¬¬ä¸€æ­¥ï¼šé¢„è®­ç»ƒå­¦ä¹ è¯­è¨€çŸ¥è¯†**

```bash
python train_pretrain.py
```

> è¿è¡Œé¢„è®­ç»ƒï¼Œå¾—åˆ° `pretrain_512.pth` é¢„è®­ç»ƒè¾“å‡ºæƒé‡

**ç¬¬äºŒæ­¥ï¼šç›‘ç£å¾®è°ƒï¼ˆä¹Ÿç§°æŒ‡ä»¤å¾®è°ƒï¼‰å­¦ä¹ å¯¹è¯æ–¹æ³•**

```bash
python train_sft.py
```

> è¿è¡Œç›‘ç£å¾®è°ƒï¼Œå¾—åˆ° `sft_512.pth` ç›‘ç£å¾®è°ƒè¾“å‡ºæƒé‡

è®­ç»ƒæ§åˆ¶å°è¾“å‡ºæ•ˆæœå¦‚ä¸‹ï¼š

```
The total number of parameters in the YuanMeng model is: 25.830 million
Epoch:[1/1](0/44160) loss:8.968 lr:0.000550000000 epoch_time:604.0min
Epoch:[1/1](100/44160) loss:5.883 lr:0.000549993674 epoch_time:45.0min
Epoch:[1/1](200/44160) loss:5.687 lr:0.000549974695 epoch_time:42.0min
Epoch:[1/1](300/44160) loss:6.516 lr:0.000549943065 epoch_time:41.0min
Epoch:[1/1](400/44160) loss:5.276 lr:0.000549898786 epoch_time:40.0min
Epoch:[1/1](500/44160) loss:5.499 lr:0.000549841859 epoch_time:40.0min
Epoch:[1/1](600/44160) loss:5.468 lr:0.000549772287 epoch_time:40.0min
...
```

<details>
  <summary>æ³¨ï¼šè®­ç»ƒé¡»çŸ¥</summary>

* æ‰€æœ‰è®­ç»ƒè¿‡ç¨‹é»˜è®¤æ¯éš” 100 æ­¥ä¿å­˜ 1 æ¬¡å‚æ•°åˆ°æ–‡ä»¶å¤¹ `./out`ï¼ˆæ¯æ¬¡éƒ½ä¼šè¦†ç›–æ—§æƒé‡ï¼‰ã€‚
* è¯¥é¡¹ç›®åªç»™å‡ºä¸¤ä¸ªé˜¶æ®µçš„è®­ç»ƒè¿‡ç¨‹ï¼Œæ–¹ä¾¿å­¦ä¹ è€…å¿«é€Ÿèµ°é€šæ¨¡å‹è®­ç»ƒã€‚å¦‚éœ€å…¶ä»–è®­ç»ƒ (LoRAã€è’¸é¦ã€å¼ºåŒ–å­¦ä¹ ã€å¾®è°ƒæ¨ç†ç­‰) å¯å‚è€ƒ [minimind](https://github.com/jingyaogong/minimind) é¡¹ç›®
* æ‰€æœ‰è®­ç»ƒè„šæœ¬å‡ä¸º Pytorch åŸç”Ÿæ¡†æ¶ï¼Œå‡æ”¯æŒå¤šå¡åŠ é€Ÿï¼Œå‡è®¾ä½ çš„è®¾å¤‡æœ‰ N (Nï¼1) å¼ æ˜¾å¡ï¼š

  ```bash
  torchrun --nproc_per_node N xxx_512.py
  ```

</details>

### â…¤ ä¸è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œå¯¹è¯

ç¡®ä¿éœ€è¦æµ‹è¯•çš„æ¨¡å‹çš„ `.pth` æƒé‡ä½äº `./out` ç›®å½•ä¸‹ï¼Œå¯ä»¥æµ‹è¯•é¢„è®­ç»ƒä¸ç›‘ç£å¾®è°ƒåçš„æ•ˆæœã€‚
é¦–å…ˆéœ€è¦åœ¨ `model_chat.py` ç¨‹åºä¸Šæ–¹è®¾ç½®å¯¹è¯å‚æ•°ï¼š

```python
mode = 1                # mode=0: æµ‹è¯•é¢„è®­ç»ƒï¼›mode=1: æµ‹è¯•ç›‘ç£å¾®è°ƒ
max_seq_len = 256       # æ¨¡å‹è¾“å…¥çš„æœ€å¤§åºåˆ—é•¿åº¦ï¼Œè¶…è¿‡éƒ¨åˆ† token å°†è¢«æˆªæ–­
max_new_tokens = 64     # æ¨¡å‹æ¯æ¬¡ç”Ÿæˆæ—¶æœ€å¤šç”Ÿæˆçš„æ–° token æ•°é‡
temperature = 0.75      # æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ï¼Œå€¼è¶Šä½è¾“å‡ºè¶Šç¡®å®š
top_p = 0.90            # æ ¸é‡‡æ ·ï¼Œä¿ç•™ç´¯è®¡æ¦‚ç‡ä¸º top_p çš„æœ€å¯èƒ½è¯æ±‡
```

è¿è¡Œå¯¹è¯ç¨‹åºï¼š

```bash
python model_chat.py
```

**é¢„è®­ç»ƒæƒé‡å¯¹è¯æ•ˆæœå¦‚ä¸‹ï¼š**

```
ğŸ¤”: æç™½æ˜¯
ğŸ¤–: å”ä»£è‘—åè¯—äººï¼Œè¢«èª‰ä¸ºâ€œè¯—ä»™â€ã€‚ä»–çš„è¯—æ­Œé£æ ¼ç‹¬ç‰¹ï¼Œä»£è¡¨ä½œæœ‰ã€Šå°†è¿›é…’ã€‹ã€ã€Šè¯—ç»ã€‹ã€ã€Šé•¿å¤œã€‹ã€ã€Šå¤œæ³Šç‰›æ¸šæ€€å¤ã€‹ã€ã€Šé•¿å¤œæ³Šç‰›æ¸šæ€€å¤ã€‹ç­‰ã€‚ä»–çš„è¯—æ­Œé£æ ¼ç‹¬å…·ç‰¹è‰²ï¼Œä»£è¡¨ä½œæœ‰ã€Šå°†è¿›é…’ã€‹ã€ã€Šå¤œ
ğŸ¤”: æœç”«æ˜¯
ğŸ¤–: å”ä»£ä¼Ÿå¤§è¯—äººï¼Œä»–å¯¹ä¸­å›½æ–‡å­¦çš„è¿½æ±‚å’Œå½±å“åŠ›æå¼ºï¼Œä½†ä»–ä¸ä»…è¿½æ±‚æ–‡å­¦çš„é­…åŠ›ï¼Œè¿˜è¿½æ±‚å¯¹ä¸­å›½æ–‡åŒ–çš„å°Šé‡å’Œçè§†ã€‚ä»–é€šè¿‡æ–‡å­¦çš„å®¡ç¾è§‚å¿µå’Œè§‚å¿µï¼Œå¯¹ä¸­å›½æ–‡åŒ–çš„ä»·å€¼å’Œæ„ä¹‰äº§ç”Ÿäº†æ·±åˆ»çš„å¯ç¤ºä¸æ€è€ƒã€‚ä»–çš„
ğŸ¤”:
```

**ç›‘ç£å¾®è°ƒæƒé‡å¯¹è¯æ•ˆæœå¦‚ä¸‹ï¼š**

```
ğŸ¤”: ä½ å–œæ¬¢åƒä»€ä¹ˆ
ğŸ¤–: ä½œä¸ºä¸€å°AIè¯­è¨€æ¨¡å‹ï¼Œæˆ‘æ²¡æœ‰å–œå¥½å’Œèº«ä½“ï¼Œå› æ­¤æ— æ³•å–œæ¬¢æˆ–ä¸å–œæ¬¢ä»»ä½•ä¸œè¥¿ã€‚ä½†æ˜¯ï¼Œæˆ‘å¯ä»¥å‘Šè¯‰ä½ ï¼Œåƒä¸œè¥¿å¯èƒ½ä¸å¤ªé€‚åˆä½ çš„å£å‘³ã€‚
ğŸ¤”: ä¸Šæµ·æœ‰ä»€ä¹ˆå¥½åƒçš„
ğŸ¤–: ä¸Šæµ·æœ‰å¾ˆå¤šå¥½åƒçš„ï¼Œæ¯”å¦‚çƒ¤é¸­ã€æ¹˜èœã€æ¹˜èœç­‰ç­‰ã€‚å¦‚æœä½ å–œæ¬¢å£å‘³è¾ƒæ·±çš„ï¼Œå¯ä»¥å°è¯•å»åƒä¸€é¡¿å°åƒã€‚æ­¤å¤–ï¼Œè¿˜æœ‰å¾ˆå¤šå…¶ä»–çš„ç¾é£Ÿï¼Œä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„å£å‘³å’Œå–œå¥½æ¥é€‰æ‹©ã€‚
ğŸ¤”: é‚£åŒ—äº¬å‘¢
ğŸ¤–: åŒ—äº¬æœ‰å¾ˆå¤šä¸é”™çš„åŒ—äº¬ç¾é£Ÿï¼Œæ¯”å¦‚çƒ¤é¸­ã€ç‚¸é…±é¢ã€ç§¦å§‹çš‡å…µé©¬ä¿‘ç­‰ç­‰ã€‚ä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½é€‰æ‹©ä¸åŒçš„å£å‘³å’Œèœå“ã€‚
ğŸ¤”:
```

> ç”±äºè®­ç»ƒæ•°æ®è§„æ¨¡ä¸æ¨¡å‹å‚æ•°è§„æ¨¡çš„é™åˆ¶ï¼Œå­¦ä¹ è€…é‡ç‚¹ä½“ä¼šæ¨¡å‹çš„è®­ç»ƒä¸æ¨ç†è¿‡ç¨‹å³å¯ï¼Œæ— éœ€å¤ªè¿‡çº ç»“æ¨¡å‹è¾“å‡ºå†…å®¹çš„å‡†ç¡®æ€§ã€‚

### â…¥ ä½¿ç”¨ LMDeploy è¿›è¡Œæ¨¡å‹æ¨ç†

LMDeploy ç”± MMDeploy å’Œ MMRazor å›¢é˜Ÿè”åˆå¼€å‘ï¼Œæ˜¯æ¶µç›–äº† LLM ä»»åŠ¡çš„å…¨å¥—è½»é‡åŒ–ã€éƒ¨ç½²å’ŒæœåŠ¡è§£å†³æ–¹æ¡ˆã€‚è¯¥å·¥å…·ç®±æä¾›ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š

* **é«˜æ•ˆçš„æ¨ç†**ï¼šPersistent Batchã€Blocked K/V Cacheã€åŠ¨æ€æ‹†åˆ†å’Œèåˆã€å¼ é‡å¹¶è¡Œã€é«˜æ•ˆçš„è®¡ç®— kernelï¼Œæ¨ç†æ€§èƒ½æ˜¯ vLLM çš„ 1.8 å€ã€‚
* **å¯é çš„é‡åŒ–**ï¼šæ”¯æŒæƒé‡é‡åŒ–å’Œ k/v é‡åŒ–ã€‚4bit æ¨¡å‹æ¨ç†æ•ˆç‡æ˜¯ FP16 ä¸‹çš„ 2.4 å€ï¼Œå·²é€šè¿‡ OpenCompass è¯„æµ‹éªŒè¯ã€‚
* **ä¾¿æ·çš„æœåŠ¡**ï¼šé€šè¿‡è¯·æ±‚åˆ†å‘æœåŠ¡ï¼Œæ”¯æŒå¤šæ¨¡å‹åœ¨å¤šæœºã€å¤šå¡ä¸Šçš„æ¨ç†æœåŠ¡ã€‚
* **æœ‰çŠ¶æ€æ¨ç†**ï¼šç¼“å­˜å¤šè½®å¯¹è¯ä¸­çš„ attention k/vï¼Œè®°ä½å†å²ä¸Šä¸‹æ–‡ï¼Œæå‡é•¿æ–‡æœ¬åœºæ™¯æ•ˆç‡ã€‚
* **å“è¶Šçš„å…¼å®¹æ€§**ï¼šæ”¯æŒ KV Cache é‡åŒ–ã€AWQ å’Œ Automatic Prefix Caching åŒæ—¶ä½¿ç”¨ã€‚

æœ¬é¡¹ç›®ä½¿ç”¨ LMDeploy æ¥å®ç°æ¨¡å‹æ¨ç†ã€é‡åŒ–ã€éƒ¨ç½²ã€‚

#### 1. è½¬æ¢æ¨¡å‹æƒé‡

å°† `sft_512.pth` æƒé‡è½¬åŒ–ä¸º Hugging Face æ ¼å¼ï¼Œè¾“å‡ºåˆ° `./Yuanmeng_Models/yuanmeng-26m-instruct`ï¼š

```bash
python convert_to_transformers.py
```

#### 2. ä½“éªŒ LMDeploy æ¨ç† Pipeline

```bash
python lmdeploy_pipeline.py
```

è¿è¡Œæ•ˆæœä¸ `model_chat.py` ä¸€è‡´ï¼Œæ›´å¤šè¯¦ç»†ç”¨æ³•è¯·å‚è§ [LMDeploy](https://github.com/InternLM/lmdeploy) é¡¹ç›®

> **æ³¨æ„ï¼š**
> ç”±äºLMDeployæ”¯æŒçš„æ¨¡å‹æœ‰é™ï¼ˆæ”¯æŒä¸»æµçš„å¤§æ¨¡å‹å¦‚Llamaã€InternLMã€Qwenã€DeepSeekç­‰ç­‰ï¼‰ï¼Œè‡ªå·±è®­ç»ƒçš„æ¨¡å‹æ— æ³•ç›´æ¥ç”¨äºLMDeployçš„éƒ¨ç½²ä¸é‡åŒ–ã€‚
è™½ç„¶LMDeployçš„å®˜æ–¹æ–‡æ¡£æœ‰ä»‹ç»å¯¹æ–°æ¨¡å‹çš„é€‚é…æ–¹æ³•ï¼Œä½†æ˜¯å†…å®¹è¿‡äºç²—ç•¥ï¼Œæ²¡æœ‰åŒ…å«å®Œæ•´çš„é€‚é…æ–¹æ³•ï¼Œå¹¶ä¸”é€‚é…æ–¹æ³•å·²ç»è¿‡æ—¶ï¼Œæ— æ³•ç”¨äºç°åœ¨çš„LMDeployç‰ˆæœ¬
æœ¬é¡¹ç›®å¯¹è®­ç»ƒåçš„"ç¼˜æ¢¦"æ¨¡å‹è¿›è¡Œäº†LMDeployçš„æ¡†æ¶é€‚é…ï¼Œä½¿å¾—ç¼˜æ¢¦æ¨¡å‹å¯ä»¥åœ¨LMDeployä¸­è¿è¡Œæ¨ç†ã€é‡åŒ–ã€éƒ¨ç½²å…¨å¥—æ“ä½œã€‚è¿™ä¹Ÿæ˜¯æœ¬é¡¹ç›®ä¸­éš¾åº¦æœ€é«˜çš„éƒ¨åˆ†ï¼Œæœ¬äººèŠ±äº†å¾ˆé•¿æ—¶é—´ï¼ˆå¤§çº¦åŠä¸ªæœˆï¼‰æ·±å…¥ç ”ç©¶LMDeployçš„æºä»£ç æ‰å®Œæˆäº†è¿™ä¸ªé€‚é…è¿‡ç¨‹ï¼Œä¸‹é¢ç¬¬â…¦éƒ¨åˆ†æœ¬äººæŠŠé€‚é…è¿‡ç¨‹çš„å…¨å¥—æ–¹æ³•åˆ†äº«å‡ºæ¥ï¼Œå¸®åŠ©å­¦ä¹ è€…ä»¬å°‘èµ°å¼¯è·¯ï¼
è‹¥å¯¹è¯¥éƒ¨åˆ†ä¸æ„Ÿå…´è¶£çš„å­¦ä¹ è€…ä»¬å¯ç›´æ¥è·³è‡³ç¬¬â…§éƒ¨åˆ†æ¥å­¦ä¹ ä½¿ç”¨LMDeployè¿›è¡Œé‡åŒ–ä¸éƒ¨ç½²ã€‚

### â…¦ é€‚é…â€œç¼˜æ¢¦â€æ¨¡å‹åˆ° LMDeploy

æœ¬èŠ‚è¯¦ç»†åˆ†äº«é€‚é…æµç¨‹ï¼Œå¸®åŠ©å­¦ä¹ è€…å¿«é€Ÿå¤ç”¨è‡ªå·±çš„æ¨¡å‹ã€‚

<details>
  <summary>æ­¥éª¤ 1ï¼šæ³¨å†Œæ¨¡å‹</summary>

```python
# åœ¨ lmdeploy/pytorch/models/module_map.py æ³¨å†Œæ¨¡å‹
MODULE_MAP.update({
    'YuanMengModel': f'{LMDEPLOY_PYTORCH_MODEL_PATH}.yuanmeng.YuanMengModel',
})
```

```python
# åœ¨ lmdeploy/pytorch/configurations æ–°å»º yuanmeng.py
from lmdeploy.pytorch.config import ModelConfig
from .builder import AutoModelConfigBuilder

class YuanMengModelConfigBuilder(AutoModelConfigBuilder):
    
    @classmethod
    def condition(cls, hf_config):
        return hf_config.model_type in ['yuanmeng']
    
    @classmethod
    def build(cls, hf_config, model_path: str = None, **kwargs):
        return ModelConfig(hidden_size=hf_config.hidden_size,
                           num_layers=hf_config.num_layers,
                           num_attention_heads=hf_config.num_attention_heads,
                           num_key_value_heads=hf_config.num_key_value_heads,
                           bos_token_id=1,
                           eos_token_id=2,
                           head_dim=hf_config.hidden_size // hf_config.num_attention_heads,
                           vocab_size=hf_config.vocab_size)
```

</details>

<details>
  <summary>æ­¥éª¤ 2ï¼šæ¨¡å‹æ¶æ„æ”¹é€ </summary>

åœ¨ `lmdeploy/pytorch/models` ä¸‹æ–°å»º `yuanmeng.py`ï¼ŒåŸºäºè®­ç»ƒæ—¶çš„ `model/model.py`ï¼Œå…·ä½“çš„é€‚é…åŒºåˆ«å¤§å®¶å¯ä»¥è‡ªè¡Œå¯¹æ¯”model/model.pyä¸lmdeploy/pytorch/models/yuanmeng.pyçš„åŒºåˆ«ï¼Œä¸»è¦é€‚é…æ“ä½œå¦‚ä¸‹ï¼š

* ä½¿ç”¨ LMDeploy æä¾›çš„ `Attention`ã€`build_down_linear`ã€`build_gateup_linear`ã€`build_o_proj`ã€`build_qkv_pro`ã€`RMSNorm` ç­‰ç®—å­è¦†ç›–åŸæœ‰æ¶æ„ã€‚
* æ·»åŠ  `get_logits`ã€`prepare_inputs_for_generation`ã€`load_weights` ç­‰æ–¹æ³•ä»¥é€‚é…è¾“å‡ºã€è¾“å…¥å’Œå‚æ•°åŠ è½½ã€‚

</details>

<details>
  <summary>æ­¥éª¤ 3ï¼šé‡åŒ–æ˜ å°„é…ç½®</summary>

```python
# åœ¨ lmdeploy/lite/apis/calibrate.py ä¸ºLAYER_TYPE_MAPã€NORM_TYPE_MAPã€HEAD_NAME_MAPæ·»åŠ æ¨¡å‹å¯¹åº”å­—æ®µï¼Œä»¥æ”¯æŒé‡åŒ–
LAYER_TYPE_MAP = {
    'YuanMengModel': 'YuanMengDecoderLayer',
...

NORM_TYPE_MAP = {
    'YuanMengModel': 'RMSNorm',
...

HEAD_NAME_MAP = {
    'YuanMengModel': 'output',
...
```
```python
# /lmdeploy/lite/quantization/awq.py é‡Œé¢çš„NORM_FCS_MAPå’ŒFC_FCS_MAPè¦å¡«ä¸Šæ¨¡å‹å•å…ƒå±‚çš„ç›¸å…³æƒé‡åå­—
NORM_FCS_MAP = {
    'MiniMindBlock': {
        'attention_norm': ['attention.wq', 'attention.wk', 'attention.wv'],
        'ffn_norm': ['feed_forward.w1', 'feed_forward.w3']
    },

FC_FCS_MAP = {
    'MiniMindBlock': {
        'attention.wv': ['attention.wo'],
        'feed_forward.w3': ['feed_forward.w2']
    },
```

ç”±äºé‡åŒ–æ—¶ä¼šé‡åˆ°æ¨¡å‹æ³¨å†Œçš„é—®é¢˜ï¼Œlmdeploy_cli.pyå®ç°äº†åœ¨lmdeployå‘½ä»¤å…¥å£å‰è¿›è¡Œæ¨¡å‹æ³¨å†Œï¼Œç”¨çš„æ˜¯åŸæœ¬çš„æ¨¡å‹ç±»
```python
from transformers import AutoConfig, AutoModelForCausalLM
from model.config import YuanMengConfig
from model.model import YuanMengModel

AutoConfig.register("yuanmeng", YuanMengConfig)
AutoModelForCausalLM.register(YuanMengConfig, YuanMengModel)

from lmdeploy.cli.entrypoint import run

if __name__ == "__main__":
    run()
```

</details>

<details>
  <summary>æ­¥éª¤ 4ï¼šè¡¥ä¸æ”¯æŒå¤šæ¶æ„</summary>

åœ¨ `lmdeploy/lite/quantization/calibration.py` ä¸­ä¿®æ”¹æ¨¡å‹è·å–é€»è¾‘ï¼š

```python
        # if type(self.model).__name__ in ('QWenLMHeadModel', 'ChatGLMForConditionalGeneration'):
        #     model = self.model.transformer
        # else:
        #     model = self.model.model
        # æ”¹äº†ä¸€ä¸‹modelçš„è·å–
        if hasattr(self.model, 'transformer'):
            model = self.model.transformer
        elif hasattr(self.model, 'model'):
            model = self.model.model
        else:
            model = self.model
```

</details>

### â…§ ä½¿ç”¨ LMDeploy è¿›è¡Œé‡åŒ–ä¸éƒ¨ç½²

#### 1. INT4 æ¨¡å‹é‡åŒ–

å¦‚æœå­¦ä¹ è€…çš„è¿œç¨‹è®¾å¤‡å¯ä»¥ç§‘å­¦ä¸Šç½‘ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œä»¥ä¸‹æŒ‡ä»¤å»è¿›è¡Œé‡åŒ–ã€‚
ç”±äºæ¨¡å‹çš„å¯¹è¯æ¨¡æ¿æ²¡æœ‰åœ¨LMDeployæ³¨å†Œï¼Œå¯ä»¥åˆ›å»ºchat_templates.jsonåœ¨LMdeployçš„ç›¸å…³æŒ‡ä»¤ä¸­ä¼ å…¥

```bash
python lmdeploy_cli.py lite auto_awq \
  Yuanmeng_Models/yuanmeng-26m-instruct \
  --work-dir Yuanmeng_Models/yuanmeng-26m-instruct-w4a16-4bit
```
* æŒ‡ä»¤è¿è¡Œç»“æŸåä¼šåœ¨Yuanmeng_Modelsç›®å½•ä¸‹å¤šäº†ä¸€ä¸ªé‡åŒ–åçš„HFæ ¼å¼çš„æ¨¡å‹æ–‡ä»¶ yuanmeng-26m-instruct-w4a16-4bit
* é‡åŒ–ç®—æ³•ä½¿ç”¨ AWQï¼ˆActivation-aware Weight Quantizationï¼‰[å‚è€ƒæ–‡çŒ®](https://arxiv.org/abs/2306.00978)

> **ç¦»çº¿æ ¡å‡†æ•°æ®ï¼š**
> è‹¥æ— æ³•ç›´æ¥ç§‘å­¦ä¸Šç½‘ï¼Œè¯·åœ¨æœ¬åœ°ä¸‹è½½ HF ç¼“å­˜åå¤åˆ¶åˆ°è¿œç¨‹ï¼š
>
> ```python
> from datasets import load_dataset
>
> traindata = load_dataset('ptb_text_only', 'penn_treebank', split='train', trust_remote_code=True)
> valdata   = load_dataset('ptb_text_only', 'penn_treebank', split='validation', trust_remote_code=True)
> ```
>
> å°† `C:/Users/Administrator/.cache/huggingface` å¤åˆ¶åˆ°è¿œç¨‹ `/root/.cache/`

é‡åŒ–å®Œæˆåï¼Œæ›´æ–° `model` å˜é‡å¹¶é‡æ–°è¿è¡Œ `lmdeploy_pipeline.py` æµ‹è¯•æ•ˆæœï¼Œä¹Ÿå¯ä»¥ç›´æ¥è¿è¡Œlmdeployçš„æŒ‡ä»¤ä¸æ¨¡å‹ç›´æ¥å¯¹è¯ï¼š

```python
# model = "Yuanmeng_Models/yuanmeng-26m-instruct"
model = "Yuanmeng_Models/yuanmeng-26m-instruct-w4a16-4bit"
```

```bash
python lmdeploy_cli.py chat \
  Yuanmeng_Models/yuanmeng-26m-instruct-w4a16-4bit \
  --chat-template chat_templates.json
```

#### 2. æ¨¡å‹éƒ¨ç½²
è¿è¡Œä»¥ä¸‹æŒ‡ä»¤è¿›è¡Œæ¨¡å‹éƒ¨ç½²ï¼Œä¼ å…¥--quant-policy 4åï¼Œæ¨¡å‹åœ¨éƒ¨ç½²æ—¶è¿˜ä¼šæ‰§è¡Œåœ¨çº¿Key-Value(KV) Cache int4é‡åŒ–ï¼Œä¼ å…¥--quant-policy 4åˆ™æ˜¯int8é‡åŒ–
```bash
python lmdeploy_cli.py serve api_server \
  Yuanmeng_Models/yuanmeng-26m-instruct-w4a16-4bit \
  --quant-policy 4 \
  --chat-template chat_templates.json
```

è¿è¡Œæ•ˆæœå¦‚ä¸‹ï¼š
```
Loading weights from safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 36.05it/s]
HINT:    Please open http://0.0.0.0:23333 in a browser for detailed api usage!!!
HINT:    Please open http://0.0.0.0:23333 in a browser for detailed api usage!!!
HINT:    Please open http://0.0.0.0:23333 in a browser for detailed api usage!!!
INFO:     Started server process [2565]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:23333 (Press CTRL+C to quit)
```

æ¨¡å‹é»˜è®¤éƒ¨ç½²åœ¨æœåŠ¡å™¨23333ç«¯å£ï¼Œéƒ¨ç½²çš„æ–¹å¼æ˜¯æš´éœ²OpenAIé£æ ¼çš„Restful APIæ¥å£ã€
æœ¬äººçš„ç¼–è¾‘å™¨æ˜¯VS Codeï¼Œæ‰§è¡Œè¯¥æŒ‡ä»¤åä¼šç›´æ¥æŠŠç«¯å£è½¬å‘åˆ°æœ¬åœ°

<p align="center">
  <img src="images/port_forwarding.png" alt="Port Forwarding"/>
</p>

æˆ–è€…å¯ä»¥è‡ªå·±æ‰‹åŠ¨è½¬å‘åˆ°æœ¬åœ°ï¼š

```bash
ssh -CNg -L 23333:127.0.0.1:23333 [user]@[host] -p [port]
```

æœ¬åœ°æµè§ˆå™¨è®¿é—®ï¼š [http://127.0.0.1:23333](http://127.0.0.1:23333) å³å¯çœ‹åˆ°æ‰€æœ‰è¢«éƒ¨ç½²çš„æ¥å£ååŠä¼ å‚

<p align="center">
  <img src="images/api_presentation.png" alt="API Presentation"/>
</p>

æœ€åï¼Œè¿˜å¯ä»¥åŸºäºå·²ç»éƒ¨ç½²å¥½çš„æ¥å£è¿è¡ŒUIç•Œé¢æ¥å’Œæ¨¡å‹è¿›è¡Œå¯¹è¯ï¼Œæå‡äº¤äº’ä½“éªŒï¼š

```bash
python lmdeploy_cli.py serve gradio http://localhost:23333
```
è¿è¡Œæ•ˆæœå¦‚ä¸‹ï¼Œé»˜è®¤éƒ¨ç½²åœ¨6006ç«¯å£
<p align="center">
  <img src="images/ui_chat.png" alt="UI Chat"/>
</p>

---

### â…¨ å®ç° CodeAct Agent

CodeActæ¶æ„ä½¿ç”¨å¯æ‰§è¡Œçš„ Python ä»£ç å°† LLM ä»£ç†çš„åŠ¨ä½œç»Ÿä¸€åˆ°ä¸€ä¸ªç»Ÿä¸€çš„åŠ¨ä½œç©ºé—´ä¸­ï¼Œé€šè¿‡é›†æˆ Python è§£é‡Šå™¨ï¼ŒCodeAct èƒ½å¤Ÿæ‰§è¡Œä»£ç åŠ¨ä½œï¼Œå¹¶åœ¨å¤šè½®äº¤äº’ä¸­æ ¹æ®æ–°çš„è§‚å¯ŸåŠ¨æ€ä¿®æ”¹å…ˆå‰åŠ¨ä½œæˆ–ç”Ÿæˆæ–°åŠ¨ä½œ [å‚è€ƒæ–‡çŒ®](https://arxiv.org/abs/2402.01030)ã€‚
é¡¹ç›®å·²åœ¨ `./codeact` ä¸­åŸºäº langgraph ä¸ langchain å®ç°ï¼Œå­¦ä¹ è€…å¯è‡ªè¡Œé˜…è¯»ã€‚
ç”±äºagentåº”ç”¨éƒ¨åˆ†ä¸æ˜¯æœ¬äººçš„å­¦ä¹ é‡ç‚¹ï¼Œæ‰€ä»¥ä»¥å®ç°è¯¥å‰æ²¿è®ºæ–‡ä¸­çš„CodeAct agentæ¶æ„ä¸ºä¸»ï¼Œå…¶ä¸­langgraphä¸langchainä¸­è¿˜æœ‰è®¸å¤šåŠŸèƒ½å’ŒçŸ¥è¯†ç‚¹ï¼Œè‹¥æœ¬äººåœ¨æœªæ¥ä¸­å­¦ä¹ æ›´å¤šçš„agenté¡¹ç›®è¿˜ä¼šä¸æ–­æ›´æ–°ã€‚

#### å‡†å¤‡å·¥ä½œ

1. éƒ¨ç½² InternLM-3 8B AWQ æ¨¡å‹ï¼š
ä½¿ç”¨LMDeployå…ˆéƒ¨ç½²ä¸€ä¸ªèƒ½åŠ›å¼ºå¤§çš„æ¨¡å‹ï¼Œè¿™é‡Œé€‰æ‹©Internlm3 8Bæ¨¡å‹ï¼Œå› ä¸ºè¿™ä¸ªæ¨¡å‹æä¾›äº†LMDeployçš„AWQé‡åŒ–ç‰ˆæœ¬ï¼Œæ— éœ€å†è‡ªè¡Œé‡åŒ–ï¼ˆä¹Ÿä¸å»ºè®®è‡ªå·±æ‰§è¡Œé‡åŒ–ï¼Œè€—æ—¶çº¦8å°æ—¶ä»¥ä¸Šï¼‰ã€‚
è¿™é‡Œä¸ºäº†é¿å¼€ç½‘ç»œçš„é™åˆ¶ï¼Œä½¿ç”¨modelscopeè¿›è¡Œæ¨¡å‹ä¸‹è½½ï¼Œæ–°å»ºä¸€ä¸ªpythonæ–‡ä»¶è¿è¡Œï¼Œä¸‹è½½æ¨¡å‹åˆ°å½“å‰é¡¹ç›®çš„æ ¹ç›®å½•ä¸‹

   ```python
   from modelscope.hub.snapshot_download import snapshot_download

   snapshot_download(
     'Shanghai_AI_Laboratory/internlm3-8b-instruct-awq',
     cache_dir='./'
   )
   ```
    ç„¶åè¿è¡Œéƒ¨ç½²
   ```bash
   python lmdeploy_cli.py serve api_server \
     Shanghai_AI_Laboratory/internlm3-8b-instruct-awq \
     --quant-policy 4
   ```

2. å®‰è£… Denoï¼šè¿™æ˜¯PyodideSandboxè¿è¡Œæ¨¡å‹è¾“å‡ºçš„pythonä»£ç æ—¶æ‰€éœ€çš„ç¯å¢ƒ

   * Windows:

     ```powershell
     irm https://deno.land/install.ps1 | iex
     ```
   * Linux:

     ```bash
     curl -fsSL https://deno.land/install.sh | sh
     ```

   > ä½†æ˜¯æœ¬äººç§Ÿçš„è®¾å¤‡ä¸çŸ¥ä¸ºä½•ä¼šæœ‰ç½‘ç»œé™åˆ¶ï¼Œæ— æ³•å®Œæˆä¸‹è½½ï¼Œå³ä½¿åœ¨æœ¬åœ°ä¸‹è½½äº†å†ä¸Šä¼ åˆ°è¿œç¨‹è®¾å¤‡ï¼Œè¿è¡ŒPyodideSandboxæ—¶ä¹Ÿä¼šæœ‰éƒ¨åˆ†åŒ…æ— æ³•ä¸‹è½½çš„ç½‘ç»œé”™è¯¯

    > äºæ˜¯æˆ‘ç›´æ¥æ”¾å¼ƒåœ¨è¿œç¨‹è®¾å¤‡æ‰§è¡Œï¼ŒæŠŠ./codeactå’Œcodeact_pipeline.pyä¸¤ä¸ªæ–‡ä»¶æ”¾åˆ°æœ¬åœ°å»è¿è¡Œï¼Œåªéœ€è¦ç¡®ä¿è¿œç¨‹è®¾å¤‡è½¬å‘äº†éƒ¨ç½²æ¨¡å‹çš„ç«¯å£å·å³å¯
    å¦‚æœå­¦ä¹ è€…çš„è¿œç¨‹è®¾å¤‡æœ‰æœ¬äººè¿™æ ·çš„é—®é¢˜ä¹Ÿå¯ä»¥æ¨¡ä»¿è¯¥æ–¹æ³•æ“ä½œã€‚

#### ç¤ºä¾‹è¿è¡Œ
å®Œæˆå‡†å¤‡å·¥ä½œåï¼Œè¿è¡ŒCodeActçš„ä¸€ä¸ªä½¿ç”¨ç¤ºä¾‹ç¨‹åºï¼ˆå»ºè®®æŠŠç«¯å£å·è½¬å‘åˆ°æœ¬åœ°ï¼Œåœ¨æœ¬åœ°è¿è¡Œï¼‰

```bash
python codeact_pipeline.py
```

#### å·¥å…·å‡½æ•°ç¤ºä¾‹
è¯¥ç¨‹åºæä¾›ç»™æ¨¡å‹ä¸€ä¸ªæ±‚å¯¼çš„æ–¹æ³•å·¥å…·
```python
# Define your tool function
def derivative(f, x, h=1e-5):
    """
    Compute the numerical derivative of function f at point x using central difference.

    Parameters:
    - f: callable, the function to differentiate
    - x: float, the point at which to evaluate the derivative
    - h: float, optional, the step size for the finite difference (default: 1e-5)

    Returns:
    - float, the approximate derivative f'(x)
    """
    return (f(x + h) - f(x - h)) / (2 * h)


tools = [derivative]
```

ç¬¬ä¸€æ¬¡è¿è¡Œcodeact_pipeline.pyæ—¶å¯èƒ½ä¼šé‡åˆ°System Messageè¿”å›ä»¥ä¸‹æŠ¥é”™ä¿¡æ¯ç»™æ¨¡å‹
```
******************************** System Message ********************************
Didn't find package packaging-24.2-py3-none-any.whl locally ...
```
åªéœ€è¦ç­‰ç›®å½•ä¸­å‡ºç°`./node_modules`æ—¶å†è¿è¡Œä¸€æ¬¡codeact_pipeline.pyå³å¯

æ¨¡å‹å¯ä»¥ä½¿ç”¨è¿™ä¸ªå·¥å…·å»å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œè¿è¡Œç¤ºä¾‹å¦‚ä¸‹:


````
ğŸ¤”: Calculate the derivative of the function f(x)=xlnx at x=Ï€. Please directly use the existing utility function 'derivative()' for computation; you do not need to import any packages or redefine itâ€”just use it directly.
ğŸ¤–:
```python
from math import pi, log

def f(x):
    return x * log(x)

# Using the provided derivative function to calculate the derivative of f at x=pi
derivative_value = derivative(f, x=pi)

print(f"The derivative of f(x)=xlnx at x=Ï€ is: {derivative_value}")

******************************** System Message ********************************

The code has been executed, and the output is as follows:
The derivative of f(x)=xlnx at x=Ï€ is: 2.144729885888985

********************************************************************************

The derivative of the function \(f(x) = x \ln x\) at \(x = \pi\) has been calculated successfully using the provided `derivative` function. The result is approximately \(2.144729885888985\). This value represents the rate of change of the function at the point where \(x = \pi\). If you need further explanation or additional steps, feel free to ask!
````

---

## è®¸å¯è¯

æœ¬ä»“åº“é‡‡ç”¨ [Apache-2.0 License](LICENSE) è®¸å¯è¯è¿›è¡Œå¼€æºã€‚